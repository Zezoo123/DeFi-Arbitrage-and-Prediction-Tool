{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit, RandomizedSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from scikeras.wrappers import KerasRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))\n",
    "\n",
    "from feature_engineering.indicators import (\n",
    "    simple_moving_average,\n",
    "    momentum,\n",
    "    cci,\n",
    "    williams_r,\n",
    "    exponential_moving_average,\n",
    "    bollinger_bands,\n",
    "    macd,\n",
    "    atr,\n",
    "    obv\n",
    ")\n",
    "from feature_engineering.time_based_features import add_time_based_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "data = pd.read_csv('../data/binance/BTC/1h.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure data is sorted by date\n",
    "data['Date'] = pd.to_datetime(data['Open Time'])\n",
    "data.sort_values('Date', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add engineered features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Simple Moving Average (SMA)\n",
    "data = simple_moving_average(data, 'Close', window=5)\n",
    "data = simple_moving_average(data, 'Close', window=10)\n",
    "\n",
    "# Apply Momentum (MTM)\n",
    "data = momentum(data, 'Close', window=5)\n",
    "data = momentum(data, 'Close', window=10)\n",
    "\n",
    "# Apply Exponential Moving Average (EMA)\n",
    "data = exponential_moving_average(data, 'Close', span=5)\n",
    "data = exponential_moving_average(data, 'Close', span=10)\n",
    "\n",
    "# Apply Bollinger Bands (BB)\n",
    "data = bollinger_bands(data, 'Close', window=20)\n",
    "\n",
    "# Apply Moving Average Convergence Divergence (MACD)\n",
    "data = macd(data, 'Close')\n",
    "\n",
    "# Apply Average True Range (ATR)\n",
    "data = atr(data, window=14)\n",
    "\n",
    "# Apply On-Balance Volume (OBV)\n",
    "data = obv(data)\n",
    "\n",
    "# Apply Commodity Channel Index (CCI)\n",
    "data = cci(data, window=20)\n",
    "\n",
    "# Apply Williams %R\n",
    "data = williams_r(data, window=14)\n",
    "\n",
    "# Apply time-based features\n",
    "data = add_time_based_features(data, 'Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create lagged features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open Time</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Close Time</th>\n",
       "      <th>Quote Asset Volume</th>\n",
       "      <th>Number of Trades</th>\n",
       "      <th>Taker Buy Base Asset Volume</th>\n",
       "      <th>...</th>\n",
       "      <th>CCI_20</th>\n",
       "      <th>Williams_%R_14</th>\n",
       "      <th>Day_of_Week</th>\n",
       "      <th>Hour_of_Day</th>\n",
       "      <th>Month_of_Year</th>\n",
       "      <th>Close_lag_1</th>\n",
       "      <th>Close_lag_2</th>\n",
       "      <th>Close_lag_3</th>\n",
       "      <th>Close_lag_4</th>\n",
       "      <th>Close_lag_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2024-09-18 19:00:00</td>\n",
       "      <td>60629.79</td>\n",
       "      <td>60745.99</td>\n",
       "      <td>59987.25</td>\n",
       "      <td>60057.99</td>\n",
       "      <td>3156.74947</td>\n",
       "      <td>2024-09-18 19:59:59.999</td>\n",
       "      <td>1.905570e+08</td>\n",
       "      <td>753066</td>\n",
       "      <td>1532.69879</td>\n",
       "      <td>...</td>\n",
       "      <td>43.420706</td>\n",
       "      <td>-58.802594</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>9</td>\n",
       "      <td>60629.79</td>\n",
       "      <td>60013.01</td>\n",
       "      <td>59915.26</td>\n",
       "      <td>59429.18</td>\n",
       "      <td>59487.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2024-09-18 20:00:00</td>\n",
       "      <td>60057.99</td>\n",
       "      <td>60320.00</td>\n",
       "      <td>59473.68</td>\n",
       "      <td>60230.01</td>\n",
       "      <td>2083.48272</td>\n",
       "      <td>2024-09-18 20:59:59.999</td>\n",
       "      <td>1.247339e+08</td>\n",
       "      <td>286619</td>\n",
       "      <td>995.87495</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.175255</td>\n",
       "      <td>-50.778524</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>60057.99</td>\n",
       "      <td>60629.79</td>\n",
       "      <td>60013.01</td>\n",
       "      <td>59915.26</td>\n",
       "      <td>59429.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2024-09-18 21:00:00</td>\n",
       "      <td>60230.01</td>\n",
       "      <td>60496.95</td>\n",
       "      <td>60168.04</td>\n",
       "      <td>60199.46</td>\n",
       "      <td>808.61440</td>\n",
       "      <td>2024-09-18 21:59:59.999</td>\n",
       "      <td>4.877547e+07</td>\n",
       "      <td>104108</td>\n",
       "      <td>372.10512</td>\n",
       "      <td>...</td>\n",
       "      <td>47.715405</td>\n",
       "      <td>-52.203564</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "      <td>60230.01</td>\n",
       "      <td>60057.99</td>\n",
       "      <td>60629.79</td>\n",
       "      <td>60013.01</td>\n",
       "      <td>59915.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2024-09-18 22:00:00</td>\n",
       "      <td>60199.46</td>\n",
       "      <td>60700.00</td>\n",
       "      <td>60194.00</td>\n",
       "      <td>60684.78</td>\n",
       "      <td>732.26197</td>\n",
       "      <td>2024-09-18 22:59:59.999</td>\n",
       "      <td>4.429355e+07</td>\n",
       "      <td>105072</td>\n",
       "      <td>401.74056</td>\n",
       "      <td>...</td>\n",
       "      <td>92.793425</td>\n",
       "      <td>-29.565258</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>60199.46</td>\n",
       "      <td>60230.01</td>\n",
       "      <td>60057.99</td>\n",
       "      <td>60629.79</td>\n",
       "      <td>60013.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2024-09-18 23:00:00</td>\n",
       "      <td>60684.78</td>\n",
       "      <td>61786.24</td>\n",
       "      <td>60680.00</td>\n",
       "      <td>61759.99</td>\n",
       "      <td>2346.43342</td>\n",
       "      <td>2024-09-18 23:59:59.999</td>\n",
       "      <td>1.437302e+08</td>\n",
       "      <td>252632</td>\n",
       "      <td>1465.86349</td>\n",
       "      <td>...</td>\n",
       "      <td>236.260632</td>\n",
       "      <td>-1.005193</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>9</td>\n",
       "      <td>60684.78</td>\n",
       "      <td>60199.46</td>\n",
       "      <td>60230.01</td>\n",
       "      <td>60057.99</td>\n",
       "      <td>60629.79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Open Time      Open      High       Low     Close      Volume  \\\n",
       "24  2024-09-18 19:00:00  60629.79  60745.99  59987.25  60057.99  3156.74947   \n",
       "25  2024-09-18 20:00:00  60057.99  60320.00  59473.68  60230.01  2083.48272   \n",
       "26  2024-09-18 21:00:00  60230.01  60496.95  60168.04  60199.46   808.61440   \n",
       "27  2024-09-18 22:00:00  60199.46  60700.00  60194.00  60684.78   732.26197   \n",
       "28  2024-09-18 23:00:00  60684.78  61786.24  60680.00  61759.99  2346.43342   \n",
       "\n",
       "                 Close Time  Quote Asset Volume  Number of Trades  \\\n",
       "24  2024-09-18 19:59:59.999        1.905570e+08            753066   \n",
       "25  2024-09-18 20:59:59.999        1.247339e+08            286619   \n",
       "26  2024-09-18 21:59:59.999        4.877547e+07            104108   \n",
       "27  2024-09-18 22:59:59.999        4.429355e+07            105072   \n",
       "28  2024-09-18 23:59:59.999        1.437302e+08            252632   \n",
       "\n",
       "    Taker Buy Base Asset Volume  ...      CCI_20  Williams_%R_14 Day_of_Week  \\\n",
       "24                   1532.69879  ...   43.420706      -58.802594           2   \n",
       "25                    995.87495  ...  -12.175255      -50.778524           2   \n",
       "26                    372.10512  ...   47.715405      -52.203564           2   \n",
       "27                    401.74056  ...   92.793425      -29.565258           2   \n",
       "28                   1465.86349  ...  236.260632       -1.005193           2   \n",
       "\n",
       "    Hour_of_Day  Month_of_Year  Close_lag_1  Close_lag_2  Close_lag_3  \\\n",
       "24           19              9     60629.79     60013.01     59915.26   \n",
       "25           20              9     60057.99     60629.79     60013.01   \n",
       "26           21              9     60230.01     60057.99     60629.79   \n",
       "27           22              9     60199.46     60230.01     60057.99   \n",
       "28           23              9     60684.78     60199.46     60230.01   \n",
       "\n",
       "    Close_lag_4  Close_lag_5  \n",
       "24     59429.18     59487.60  \n",
       "25     59915.26     59429.18  \n",
       "26     60013.01     59915.26  \n",
       "27     60629.79     60013.01  \n",
       "28     60057.99     60629.79  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for lag in range(1, 6):\n",
    "    data[f'Close_lag_{lag}'] = data['Close'].shift(lag)\n",
    "                                                   \n",
    "data.dropna(inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get features and split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data[['Close_lag_1', 'Close_lag_2', 'Close_lag_3', 'Close_lag_4', 'Close_lag_5',\n",
    "                 'SMA_5', 'SMA_10', 'MTM_5', 'MTM_10', 'EMA_5', 'EMA_10', 'MA', 'UB', 'LB', 'MACD',\n",
    "                 'Signal_Line', 'ATR_14', 'OBV', 'CCI_20', 'Williams_%R_14', \n",
    "                 'Day_of_Week', 'Hour_of_Day', 'Month_of_Year']]\n",
    "target = data['Close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_features = StandardScaler()\n",
    "features_scaled = scaler_features.fit_transform(features)\n",
    "\n",
    "scaler_target = StandardScaler()\n",
    "target_scaled = scaler_target.fit_transform(target.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create sequences for lstm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(features, target, time_steps=10):\n",
    "    X, y= [], []\n",
    "    for i in range(len(features) - time_steps):\n",
    "        X.append(features[i:i + time_steps])\n",
    "        y.append(target[i + time_steps])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "time_steps = 10\n",
    "X, y = create_sequences(features_scaled, target_scaled, time_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (685, 10, 23)\n"
     ]
    }
   ],
   "source": [
    "print(f'X shape: {X.shape}')  # Should be (number_of_samples, time_steps, number_of_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(50, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.5250 - val_loss: 0.1183\n",
      "Epoch 2/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1386 - val_loss: 0.0513\n",
      "Epoch 3/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0800 - val_loss: 0.0346\n",
      "Epoch 4/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0612 - val_loss: 0.0333\n",
      "Epoch 5/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0576 - val_loss: 0.0337\n",
      "Epoch 6/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0619 - val_loss: 0.0308\n",
      "Epoch 7/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0546 - val_loss: 0.0292\n",
      "Epoch 8/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0508 - val_loss: 0.0277\n",
      "Epoch 9/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0428 - val_loss: 0.0278\n",
      "Epoch 10/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0446 - val_loss: 0.0268\n",
      "Epoch 11/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0429 - val_loss: 0.0241\n",
      "Epoch 12/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0401 - val_loss: 0.0282\n",
      "Epoch 13/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0377 - val_loss: 0.0244\n",
      "Epoch 14/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0385 - val_loss: 0.0253\n",
      "Epoch 15/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0432 - val_loss: 0.0248\n",
      "Epoch 16/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0425 - val_loss: 0.0249\n",
      "Epoch 17/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0432 - val_loss: 0.0229\n",
      "Epoch 18/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0484 - val_loss: 0.0244\n",
      "Epoch 19/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0397 - val_loss: 0.0213\n",
      "Epoch 20/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0333 - val_loss: 0.0232\n",
      "Epoch 21/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0410 - val_loss: 0.0219\n",
      "Epoch 22/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0391 - val_loss: 0.0273\n",
      "Epoch 23/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0425 - val_loss: 0.0222\n",
      "Epoch 24/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0358 - val_loss: 0.0217\n",
      "Epoch 25/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0300 - val_loss: 0.0222\n",
      "Epoch 26/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0413 - val_loss: 0.0209\n",
      "Epoch 27/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0301 - val_loss: 0.0210\n",
      "Epoch 28/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0329 - val_loss: 0.0218\n",
      "Epoch 29/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0303 - val_loss: 0.0231\n",
      "Epoch 30/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0425 - val_loss: 0.0218\n",
      "Epoch 31/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0346 - val_loss: 0.0220\n",
      "Epoch 32/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0290 - val_loss: 0.0224\n",
      "Epoch 33/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0368 - val_loss: 0.0209\n",
      "Epoch 34/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0358 - val_loss: 0.0204\n",
      "Epoch 35/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0343 - val_loss: 0.0256\n",
      "Epoch 36/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0344 - val_loss: 0.0214\n",
      "Epoch 37/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0338 - val_loss: 0.0197\n",
      "Epoch 38/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0272 - val_loss: 0.0188\n",
      "Epoch 39/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0305 - val_loss: 0.0209\n",
      "Epoch 40/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0281 - val_loss: 0.0200\n",
      "Epoch 41/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0349 - val_loss: 0.0191\n",
      "Epoch 42/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0321 - val_loss: 0.0220\n",
      "Epoch 43/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0271 - val_loss: 0.0213\n",
      "Epoch 44/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0307 - val_loss: 0.0226\n",
      "Epoch 45/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0293 - val_loss: 0.0194\n",
      "Epoch 46/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0292 - val_loss: 0.0193\n",
      "Epoch 47/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0258 - val_loss: 0.0192\n",
      "Epoch 48/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0320 - val_loss: 0.0211\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Mean Squared Error: 68138.57325124556\n",
      "R^2 Score: 0.9775476389429636\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate the model\n",
    "history = model.fit(X_train, y_train, validation_split=0.2, epochs=100, batch_size=32, callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred_scaled = model.predict(X_test)\n",
    "y_pred = scaler_target.inverse_transform(y_pred_scaled)\n",
    "y_test_original = scaler_target.inverse_transform(y_test)\n",
    "mse = mean_squared_error(y_test_original, y_pred)\n",
    "r2 = r2_score(y_test_original, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'R^2 Score: {r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'iloc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [93], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train_index, test_index \u001b[38;5;129;01min\u001b[39;00m tscv\u001b[38;5;241m.\u001b[39msplit(X_train):\n\u001b[1;32m      5\u001b[0m     X_train_cv, X_test_cv \u001b[38;5;241m=\u001b[39m X_train[train_index], X_train[test_index]\n\u001b[0;32m----> 6\u001b[0m     y_train_cv, y_test_cv \u001b[38;5;241m=\u001b[39m \u001b[43my_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m[train_index], y_train\u001b[38;5;241m.\u001b[39miloc[test_index]\n\u001b[1;32m      8\u001b[0m     model_cv \u001b[38;5;241m=\u001b[39m Sequential()\n\u001b[1;32m      9\u001b[0m     model_cv\u001b[38;5;241m.\u001b[39madd(Dense(\u001b[38;5;241m64\u001b[39m, input_dim\u001b[38;5;241m=\u001b[39mX_train_cv\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'iloc'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Perform cross-validation with TimeSeriesSplit\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "cv_mse = []\n",
    "for train_index, test_index in tscv.split(X_train):\n",
    "    X_train_cv, X_test_cv = X_train[train_index], X_train[test_index]\n",
    "    y_train_cv, y_test_cv = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "    \n",
    "    model_cv = Sequential()\n",
    "    model_cv.add(Dense(64, input_dim=X_train_cv.shape[1], activation='relu'))\n",
    "    model_cv.add(Dropout(0.2))\n",
    "    model_cv.add(Dense(32, activation='relu'))\n",
    "    model_cv.add(Dropout(0.2))\n",
    "    model_cv.add(Dense(1))\n",
    "    \n",
    "    model_cv.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    model_cv.fit(X_train_cv, y_train_cv, epochs=100, batch_size=32, verbose=0)\n",
    "    \n",
    "    y_pred_cv = model_cv.predict(X_test_cv)\n",
    "    mse_cv = mean_squared_error(y_test_cv, y_pred_cv)\n",
    "    cv_mse.append(mse_cv)\n",
    "\n",
    "print(f'TimeSeriesSplit Cross-Validation MSE: {cv_mse}')\n",
    "print(f'Mean TimeSeriesSplit Cross-Validation MSE: {np.mean(cv_mse)}')\n",
    "print(f'Standard Deviation of TimeSeriesSplit Cross-Validation MSE: {np.std(cv_mse)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x16bdcdfc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found: {'model__units': 50, 'model__optimizer': 'adam', 'model__dropout_rate': 0.2, 'epochs': 100, 'batch_size': 64}\n",
      "Epoch 1/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - loss: 0.5216 - val_loss: 0.1178\n",
      "Epoch 2/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1461 - val_loss: 0.0843\n",
      "Epoch 3/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1298 - val_loss: 0.0565\n",
      "Epoch 4/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1081 - val_loss: 0.0479\n",
      "Epoch 5/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0805 - val_loss: 0.0340\n",
      "Epoch 6/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0608 - val_loss: 0.0288\n",
      "Epoch 7/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0622 - val_loss: 0.0275\n",
      "Epoch 8/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0518 - val_loss: 0.0344\n",
      "Epoch 9/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0586 - val_loss: 0.0286\n",
      "Epoch 10/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0476 - val_loss: 0.0256\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "Mean Squared Error: 365910.18225152564\n",
      "R^2 Score: 0.8794288295989956\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the model creation function\n",
    "def create_model(units=50, dropout_rate=0.2, optimizer='adam'):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(LSTM(units, return_sequences=False))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Wrap the model using KerasRegressor\n",
    "model = KerasRegressor(model=create_model, epochs=100, batch_size=32, verbose=0)\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_dist = {\n",
    "    'model__units': [50, 100, 150],\n",
    "    'model__dropout_rate': [0.2, 0.3, 0.4],\n",
    "    'model__optimizer': ['adam', 'rmsprop'],\n",
    "    'epochs': [50, 100],\n",
    "    'batch_size': [32, 64]\n",
    "}\n",
    "\n",
    "# Perform Randomized Search\n",
    "random_search = RandomizedSearchCV(estimator=model, param_distributions=param_dist, n_iter=10, cv=3, verbose=1, n_jobs=-1)\n",
    "random_search_result = random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = random_search_result.best_params_\n",
    "print(f'Best parameters found: {best_params}')\n",
    "\n",
    "# Train the model with the best parameters\n",
    "best_model = create_model(units=best_params['model__units'], dropout_rate=best_params['model__dropout_rate'], optimizer=best_params['model__optimizer'])\n",
    "history = best_model.fit(X_train, y_train, validation_split=0.2, epochs=best_params['epochs'], batch_size=best_params['batch_size'], callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred_scaled = best_model.predict(X_test)\n",
    "y_pred = scaler_target.inverse_transform(y_pred_scaled)\n",
    "y_test_original = scaler_target.inverse_transform(y_test)\n",
    "\n",
    "mse = mean_squared_error(y_test_original, y_pred)\n",
    "r2 = r2_score(y_test_original, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'R^2 Score: {r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
